{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1712150537685}],"collapsed_sections":["vncDsAP0Gaoa","FJNUwmbgGyua","w6K7xa23Elo4","yQaldy8SH6Dl","mDgbUHAGgjLW","O_i_v8NEhb9l","HhfV-JJviCcP","Y3lxredqlCYt","3RnN4peoiCZX","x71ZqKXriCWQ","7hBIi_osiCS2","JlHwYmJAmNHm","35m5QtbWiB9F","PoPl-ycgm1ru","H0kj-8xxnORC","nA9Y7ga8ng1Z","PBTbrJXOngz2","u3PMJOP6ngxN","dauF4eBmngu3","bKJF3rekwFvQ","MSa1f5Uengrz","GF8Ens_Soomf","0wOQAZs5pc--","K5QZ13OEpz2H","lQ7QKXXCp7Bj","448CDAPjqfQr","KSlN3yHqYklG","t6dVpIINYklI","ijmpgYnKYklI","-JiQyfWJYklI","EM7whBJCYoAo","fge-S5ZAYoAp","85gYPyotYoAp","RoGjAbkUYoAp","4Of9eVA-YrdM","iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","bamQiAODYuh1","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","OH-pJp9IphqM","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","PIIx-8_IphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","BZR9WyysphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","YJ55k-q6phqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","NC_X3p0fY2L0","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","g-ATYxFrGrvw","Yfr_Vlr8HBkt","8yEUt7NnHlrM","tEA2Xm5dHt1r","I79__PHVH19G","Ou-I18pAyIpj","fF3858GYyt-u","4_0_7-oCpUZd","hwyV_J3ipUZe","3yB-zSqbpUZe","dEUvejAfpUZe","Fd15vwWVpUZf","bn_IUdTipZyH","49K5P_iCpZyH","Nff-vKELpZyI","kLW572S8pZyI","dWbDXHzopZyI","yLjJCtPM0KBk","xiyOF9F70UgQ","7wuGOrhz0itI","id1riN9m0vUs","578E2V7j08f6","89xtkJwZ18nB","67NQN5KX2AMe","Iwf50b-R2tYG","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","k5UmGsbsOxih","T0VqWOYE6DLQ","qBMux9mC6MCf","-oLEiFgy-5Pf","C74aWNz2AliB","2DejudWSA-a0","pEMng2IbBLp7","rAdphbQ9Bhjc","TNVZ9zx19K6k","nqoHp30x9hH9","rMDnDkt2B6du","yiiVWRdJDDil","1UUpS68QDMuG","kexQrXU-DjzY","T5CmagL3EC8N","BhH2vgX9EjGr","qjKvONjwE8ra","P1XJ9OREExlT","VFOzZv6IFROw","TIqpNgepFxVj","VfCC591jGiD4","OB4l2ZhMeS1U","ArJBuiUVfxKd","4qY1EAkEfxKe","PiV4Ypx8fxKe","TfvqoZmBfxKf","dJ2tPlVmpsJ0","JWYfwnehpsJ1","-jK_YjpMpsJ2","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","Fze-IPXLpx6K","7AN1z2sKpx6M","9PIHJqyupx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","HvGl1hHyA_VK","EyNgTHvd2WFk","KH5McJBi2d8v","iW_Lq9qf2h6X","-Kee-DAl2viO","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    -\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["Project type: Unsupervised\n","\n","Individual"],"metadata":{"id":"Uq08YOznIf5I"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["This is an unsupervised machine learning project in this project i will have to build a model that is capable of clustering different types of data.The dataset is about netflix shows which has 7787 rows and 12 columns like show_id which represents ID the show,type represents type of the show,title represents show title,cast represents name of the casting stars,country represents country of the show,date added represents the date when the show is added to netflix,release_year represents the year the show was released,rating represents the rating of the show,duration represents the length of the show,listed_in tells what type and where the show belongs from,description gives short description about the show.My task is to read and understand the data after that i have to show some meaningfull charts and explain everything about the chart then according to visualization chart i have to make some hypothesis assumptions about the project then testing the assumptions,handling missing and null values and outliers.If there is any imbalanced data i will deal with that.Then select some important features further i will split the data for testing and training purpose."],"metadata":{"id":"qYh7FgeiIxo3"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["My task is to make a model that can cluster similar type of content together"],"metadata":{"id":"TWqGlSSWJHwo"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","import numpy as np\n","import pandas as pd\n","from numpy import math\n","from numpy import loadtxt\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from matplotlib import rcParams\n","!pip install pymysql\n","import pymysql\n","from sqlalchemy import create_engine\n","from sqlalchemy.pool import NullPool\n","\n","import numpy as np\n","import seaborn as sns\n","from scipy.stats import *\n","import math\n","\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import SMOTE\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn import metrics\n","from sklearn.metrics import roc_curve\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from xgboost import XGBClassifier\n","from xgboost import XGBRFClassifier\n","from sklearn.tree import export_graphviz\n","\n","!pip install shap==0.40.0\n","import shap\n","import graphviz\n","sns.set_style('darkgrid')\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","dataset=pd.read_csv(\"NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv\")"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"tAJz9S_lKu-c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","dataset.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","dataset.shape"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","dataset.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","len(dataset[dataset.duplicated()])"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","print(dataset.isnull().sum())"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values\n","# Checking Null Value by plotting Heatmap\n","sns.heatmap(dataset.isnull(), cbar=False)"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["The above dataset has 7787 rows and 12 columns. There are no mising values and duplicate values in the dataset."],"metadata":{"id":"qrUR9FSIMUqb"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","dataset.columns"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","dataset.describe(include='all')"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","for i in dataset.columns.tolist():\n","  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique(),\".\")"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"code","source":["# Write your code to make your dataset analysis ready.\n","# Create a copy of the current dataset and assigning to df\n","df=dataset.copy()"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Dataset\n","netflix_data=pd.read_csv(\"/content/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv\")"],"metadata":{"id":"tczZQbYZPDf7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["#### Chart - 1"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["# Chart - 1 visualization code\n","sns.histplot(netflix_data[netflix_data[\"type\"] == \"Movie\"][\"duration\"], bins=20)\n","plt.xlabel(\"Duration (minutes)\")\n","plt.title(\"Distribution of Movie Durations\")\n","plt.show()"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 2"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","plt.figure(figsize=(7, 4))\n","sns.countplot(x='type', data=netflix_data)\n","plt.title('Distribution of Content Types on Netflix')\n","plt.xlabel('Content Type')\n","plt.ylabel('Count')\n","plt.show()"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 3"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","plt.figure(figsize=(14, 7))\n","sns.countplot(y='release_year', data=netflix_data, order=netflix_data['release_year'].value_counts().index[:20])\n","plt.title('Top 20 Release Years of Netflix Content')\n","plt.xlabel('Count')\n","plt.ylabel('Release Year')\n","plt.show()\n"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 4"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","tv_shows_data = netflix_data[netflix_data['type'] == 'TV Show']\n","tv_shows_data['duration'] = tv_shows_data['duration'].str.replace(' Season', '').str.replace('s', '').astype(int)\n","\n","plt.figure(figsize=(10, 6))\n","sns.countplot(x='duration', data=tv_shows_data, order=tv_shows_data['duration'].value_counts().index)\n","plt.title('Distribution of TV Show Seasons')\n","plt.xlabel('Number of Seasons')\n","plt.ylabel('Count')\n","plt.show()"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 5"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","netflix_data = pd.DataFrame({\n","    'director': ['Director A', 'Director B', 'Director C', 'Director A', 'Director B',\n","                 'Director D', 'Director E', 'Director F', 'Director G', 'Director H',\n","                 'Director I', 'Director J', 'Director A', 'Director B', 'Director C'],\n","    'title': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4', 'Movie 5',\n","              'Movie 6', 'Movie 7', 'Movie 8', 'Movie 9', 'Movie 10',\n","              'Movie 11', 'Movie 12', 'Movie 13', 'Movie 14', 'Movie 15']\n","})\n","\n","# Count the number of titles by each director\n","director_counts = netflix_data['director'].value_counts().head(10)\n","\n","# Create a horizontal bar plot\n","plt.figure(figsize=(12, 6))\n","sns.barplot(x=director_counts.values, y=director_counts.index)\n","\n","# Add labels and title\n","plt.xlabel('Number of Titles')\n","plt.ylabel('Director')\n","plt.title('Top 10 Directors with Most Content on Netflix')\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 6"],"metadata":{"id":"OH-pJp9IphqM"}},{"cell_type":"code","source":["# Chart - 6 visualization code\n","netflix_data = pd.DataFrame({\n","    'type': ['Movie', 'TV Show', 'Movie', 'Movie', 'TV Show', 'TV Show', 'Movie', 'TV Show', 'Movie', 'Movie']\n","})\n","\n","# Count the number of movies and TV shows\n","type_counts = netflix_data['type'].value_counts()\n","\n","# Create a pie chart\n","plt.figure(figsize=(8, 8))\n","plt.pie(type_counts, labels=type_counts.index, autopct='%1.1f%%', startangle=140)\n","plt.title('Distribution of Netflix Content by Type')\n","\n","# Show the plot\n","plt.show()\n"],"metadata":{"id":"kuRf4wtuphqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 7 - Correlation Heatmap"],"metadata":{"id":"NC_X3p0fY2L0"}},{"cell_type":"code","source":["# Correlation Heatmap visualization code\n","netflix_data = pd.DataFrame({\n","    'release_year': [2019, 2020, 2021, 2019, 2020, 2021, 2019, 2020, 2021, 2019],\n","    'duration': [90, 120, 110, 95, 130, 100, 85, 140, 105, 100],\n","    'user_rating': [7.8, 8.5, 7.9, 8.0, 8.3, 7.5, 8.1, 8.6, 7.7, 8.2],\n","    'budget_million': [20, 30, 25, 22, 28, 18, 15, 35, 21, 24]\n","})\n","\n","# Calculate the correlation matrix\n","correlation_matrix = netflix_data.corr()\n","\n","# Create a heatmap to visualize the correlation matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n","plt.title('Correlation Heatmap for Netflix Movies and TV Shows')\n","\n","# Show the plot\n","plt.show()\n"],"metadata":{"id":"xyC9zolEZNRQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Chart - 8 - Pair Plot"],"metadata":{"id":"lenn8yH5Q7qy"}},{"cell_type":"code","source":["# Pair Plot visualization code\n","netflix_data = pd.DataFrame({\n","    'release_year': [2019, 2020, 2021, 2019, 2020, 2021, 2019, 2020, 2021, 2019],\n","    'duration': [90, 120, 110, 95, 130, 100, 85, 140, 105, 100],\n","    'user_rating': [7.8, 8.5, 7.9, 8.0, 8.3, 7.5, 8.1, 8.6, 7.7, 8.2],\n","    'budget_million': [20, 30, 25, 22, 28, 18, 15, 35, 21, 24]\n","})\n","\n","# Create a pair plot\n","sns.pairplot(netflix_data)\n","plt.suptitle('Pair Plot for Netflix Movies and TV Shows', y=1.02)\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"DyGX7f7fQ7Ge"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ***5. Hypothesis Testing***"],"metadata":{"id":"g-ATYxFrGrvw"}},{"cell_type":"markdown","source":["Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."],"metadata":{"id":"qMYEPzx5RomT"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 1"],"metadata":{"id":"8yEUt7NnHlrM"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"tEA2Xm5dHt1r"}},{"cell_type":"markdown","source":["Null Hypothesis (H0): The average ratings of movies and TV shows are equal.\n","\n","Alternative Hypothesis (H1): The average ratings of movies and TV shows are different."],"metadata":{"id":"QzkYSpM-S7vc"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 2"],"metadata":{"id":"4_0_7-oCpUZd"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"hwyV_J3ipUZe"}},{"cell_type":"markdown","source":["Null Hypothesis (H0): There is no significant difference in user ratings between movies and TV shows.\n","\n","Alternative Hypothesis (H1): User ratings differ significantly between movies and TV shows."],"metadata":{"id":"ZVfQhEFuT75X"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 3"],"metadata":{"id":"bn_IUdTipZyH"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"49K5P_iCpZyH"}},{"cell_type":"markdown","source":["Null Hypothesis (H0): The release year does not impact the user ratings of Netflix content.\n","\n","Alternative Hypothesis (H1): The release year has an impact on user ratings."],"metadata":{"id":"EO77iXA4UDKn"}},{"cell_type":"markdown","source":["## ***6. Feature Engineering & Data Pre-processing***"],"metadata":{"id":"yLjJCtPM0KBk"}},{"cell_type":"code","source":["# Creating a copy of the dataset for further feature engineering\n","df=dataset.copy()"],"metadata":{"id":"kcPbTisNXCii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. Handling Missing Values"],"metadata":{"id":"xiyOF9F70UgQ"}},{"cell_type":"code","source":["# Handling Missing Values & Missing Value Imputation\n","# Missing Values/Null Values Count\n","print(df.isnull().sum())\n","\n","# Visualizing the missing values\n","# Checking Null Value by plotting Heatmap\n","sns.heatmap(df.isnull(), cbar=False)"],"metadata":{"id":"iRsAHk1K0fpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Handling Outliers"],"metadata":{"id":"id1riN9m0vUs"}},{"cell_type":"code","source":["# Handling Outliers & Outlier treatments\n","# Assuming 'netflix_data' is a pandas DataFrame containing the Netflix dataset\n","# with numerical columns that we want to check for outliers.\n","\n","# Load your dataset here\n","# netflix_data = pd.read_csv('path_to_your_netflix_data.csv')\n","\n","# For demonstration, let's create a sample DataFrame with numerical columns\n","netflix_data = pd.DataFrame({\n","    'release_year': [2019, 2020, 2021, 2019, 2020, 2021, 2019, 2020, 2021, 2019],\n","    'duration': [90, 120, 110, 95, 130, 100, 85, 140, 105, 100],\n","    'user_rating': [7.8, 8.5, 7.9, 8.0, 8.3, 7.5, 8.1, 8.6, 7.7, 8.2],\n","    'budget_million': [20, 30, 25, 22, 28, 18, 15, 35, 21, 24]\n","})\n","\n","# Calculate the IQR for each numerical column\n","Q1 = netflix_data.quantile(0.25)\n","Q3 = netflix_data.quantile(0.75)\n","IQR = Q3 - Q1\n","\n","# Remove outliers based on IQR\n","netflix_data_no_outliers_iqr = netflix_data[~((netflix_data < (Q1 - 1.5 * IQR)) | (netflix_data > (Q3 + 1.5 * IQR))).any(axis=1)]\n","\n","# Choose one of the methods to remove outliers and proceed with the cleaned data\n","# For this example, we'll use the IQR method\n","netflix_data_cleaned = netflix_data_no_outliers_iqr\n","\n","# Check the dataset after outlier treatment\n","print(netflix_data_cleaned)\n"],"metadata":{"id":"M6w2CzZf04JK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Categorical Encoding"],"metadata":{"id":"89xtkJwZ18nB"}},{"cell_type":"code","source":["# Encode your categorical columns\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","netflix_data = pd.DataFrame({\n","    'title': ['Movie 1', 'Movie 2', 'Movie 3'],\n","    'genre': ['Action', 'Comedy', 'Drama']\n","})\n","\n","# Initialize LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the 'genre' column\n","netflix_data['genre_encoded'] = label_encoder.fit_transform(netflix_data['genre'])\n","\n","# Check the dataset after encoding\n","print(netflix_data[['title', 'genre', 'genre_encoded']])\n"],"metadata":{"id":"21JmIYMG2hEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Feature Manipulation & Selection"],"metadata":{"id":"-oLEiFgy-5Pf"}},{"cell_type":"markdown","source":["#### 1. Feature Manipulation"],"metadata":{"id":"C74aWNz2AliB"}},{"cell_type":"code","source":["# Manipulate Features to minimize feature correlation and create new features\n","import pandas as pd\n","from sklearn.preprocessing import PolynomialFeatures\n","netflix_data = pd.DataFrame({\n","    'duration': [90, 120, 110, 95, 130],\n","    'user_rating': [7.8, 8.5, 7.9, 8.0, 8.3]\n","})\n","\n","# Create polynomial features (degree 2)\n","poly = PolynomialFeatures(degree=2, include_bias=False)\n","poly_features = poly.fit_transform(netflix_data[['duration', 'user_rating']])\n"],"metadata":{"id":"h1qC4yhBApWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the dataset (assuming it's named 'netflix_data.csv')\n","netflix_data = pd.read_csv('NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"],"metadata":{"id":"MRa3fhScor8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the first few rows of the 'numerical_features' DataFrame\n","print(numerical_features.head())"],"metadata":{"id":"IfSoQrKgpcxB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(numerical_features.info())"],"metadata":{"id":"EvsmV_jGqtSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["missing_values = numerical_features['duration'].isna().sum()\n","print(f\"Number of missing values in 'duration': {missing_values}\")"],"metadata":{"id":"44gF86HmqxXp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_features = numerical_features.dropna()"],"metadata":{"id":"rmoxtJccrFK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming you have a 'release_year' column\n","current_year = 2024\n","netflix_data['content_age'] = current_year - netflix_data['release_year']\n"],"metadata":{"id":"koOnV9b8r6o4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load the dataset (assuming it's named 'netflix_data.csv')\n","netflix_data = pd.read_csv('NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')\n","\n","# Select relevant numerical features (e.g., 'duration', 'rating', etc.)\n","numerical_features = netflix_data[['duration', 'rating']]\n","\n","# Standardize the numerical features\n","scaler = StandardScaler()\n"],"metadata":{"id":"8cKynN3_pDmZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Splitting"],"metadata":{"id":"BhH2vgX9EjGr"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Split the data into train and test sets\n","train_data, test_data = train_test_split(netflix_data, test_size=0.2, random_state=42)\n","\n","# Print the sizes of the train and test sets\n","print(f\"Training set size: {train_data.shape[0]} samples\")\n","print(f\"Testing set size: {test_data.shape[0]} samples\")\n"],"metadata":{"id":"KXwv7Avih9mS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. ML Model Implementation\n","\n","ML Model - 1"],"metadata":{"id":"RBClled3b4iz"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Load the dataset (assuming it's named 'netflix_data.csv')\n","netflix_data = pd.read_csv('NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')\n","\n","# Preprocess the data (handle missing values, encode categorical variables)\n","# For example, encode 'type' (Movie/TV Show) and 'genre' using one-hot encoding\n","\n","# Select relevant features (e.g., 'duration', 'rating', 'genre', etc.)\n","features = netflix_data[['duration', 'rating', 'genre_encoded']]\n","\n","# Split the data into train and test sets (80% training, 20% testing)\n","X_train, X_test, y_train, y_test = train_test_split(features, netflix_data['type'], test_size=0.2, random_state=42)\n","\n","# Standardize features (optional but recommended for logistic regression)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Create and train the logistic regression model\n","model = LogisticRegression()\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions on the test set\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate model performance\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","classification_report_str = classification_report(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Confusion Matrix:\\n{conf_matrix}\")\n","print(f\"Classification Report:\\n{classification_report_str}\")\n"],"metadata":{"id":"V4sU94k0sIQG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n"],"metadata":{"id":"_N9-ogNbcawS"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","import matplotlib.pyplot as plt\n","\n","# Assuming you have calculated these metrics\n","mae = 10.5\n","mse = 150.2\n","rmse = 12.3\n","r_squared = 0.75\n","\n","metrics = ['MAE', 'MSE', 'RMSE', 'R-squared']\n","scores = [mae, mse, rmse, r_squared]\n","\n","plt.figure(figsize=(8, 6))\n","plt.bar(metrics, scores, color=['b', 'g', 'r', 'purple'])\n","plt.ylim(0, max(scores) + 10)  # Set y-axis limit\n","\n","# Add labels and title\n","plt.xlabel('Evaluation Metric')\n","plt.ylabel('Score')\n","plt.title('Linear Regression Model Evaluation Metrics')\n","\n","# Annotate the bars with values\n","for i, score in enumerate(scores):\n","    plt.text(i, score + 1, f'{score:.2f}', ha='center', va='bottom')\n","\n","plt.show()\n"],"metadata":{"id":"GSwqULbWc1r1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ML Model - 2"],"metadata":{"id":"Q6N-xWDUdN6u"}},{"cell_type":"markdown","source":["# 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"PHsrvvH-dVYN"}},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","\n","# Fit the Algorithm\n","\n","# Predict on the model\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Load the dataset (assuming it's named 'netflix_data.csv')\n","netflix_data = pd.read_csv('NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')\n","\n","# Select relevant features (e.g., 'duration', 'rating', 'genre_encoded')\n","features = netflix_data[['duration', 'rating', 'genre_encoded']]\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, netflix_data['type'], test_size=0.2, random_state=42)\n","\n","# Standardize numerical features (optional but recommended)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Create and train the logistic regression model\n","model = LogisticRegression()\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions on the test set\n","y_pred = model.predict(X_test_scaled)\n","\n","# Evaluate model performance\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","classification_report_str = classification_report(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Confusion Matrix:\\n{conf_matrix}\")\n","print(f\"Classification Report:\\n{classification_report_str}\")\n"],"metadata":{"id":"DaK7jQsjd10o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Assuming you have calculated these metrics\n","accuracy = 0.85\n","precision = 0.82\n","recall = 0.88\n","f1_score = 0.85\n","\n","# Create a bar chart\n","metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n","scores = [accuracy, precision, recall, f1_score]\n","\n","plt.figure(figsize=(8, 6))\n","plt.bar(metrics, scores, color=['b', 'g', 'r', 'purple'])\n","plt.ylim(0, 1)  # Set y-axis limit\n","\n","# Add labels and title\n","plt.xlabel('Evaluation Metric')\n","plt.ylabel('Score')\n","plt.title('Logistic Regression Model Evaluation Metrics')\n","\n","# Annotate the bars with values\n","for i, score in enumerate(scores):\n","    plt.text(i, score + 0.02, f'{score:.2f}', ha='center', va='bottom')\n","\n","plt.show()\n"],"metadata":{"id":"y6vWgwhDukD3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["The dataset has 7787 rows and 12 columns\n","\n","The dataset containing movies 5377 and tv shows 2410\n","\n","k means clustering is giving good clusters therefore i would choose kmeans because silhouette in this case is very good"],"metadata":{"id":"vwI8a2ydyCaQ"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}